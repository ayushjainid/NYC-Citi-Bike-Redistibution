{
  "metadata": {
    "name": "bdad_project",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Better Biking - Real-time city-wide bike re-distribution by incentivizing riders to drop bikes at high-demand locations\n\n## Team Members\n- Anubhav Jain (aj3187)\n- Ayush Jain (aj3152)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Project Introduction\nIn this project, we are trying to identify high demand biking stations in real time and incentivizing riders to drop bikes at these high-demand locations in a radius of 1 mile.\n\nOur code allows users to enter their locations in the form of latitude and longitude and produces a list of stations near that location along with the discounts offered at each station.\n\nIn case a user wants the predicted discount at some other time, we allow the user to enter a time and then try to predict what discounts would be offered at that time\n\n### Data Sources\nWe are using the real-time data feed from the Citi Bike General Bikeshare Feed Specification (https://github.com/MobilityData/gbfs/blob/master/gbfs.md) to fetch following data streams:\n* Citi-bike station status (https://gbfs.citibikenyc.com/gbfs/en/station_status.json) - This data gives provides real-time bike and e-bike availability information \n* Citi-bike station information (https://gbfs.citibikenyc.com/gbfs/en/station_information.json) - This data provides the real-time station information like station id, name, location and total capacity"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Imports"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import okhttp3.{Headers, OkHttpClient, Request, Response}\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.api.java.UDF1\nimport org.apache.spark.sql.functions.{col, udf, from_json, explode}\nimport org.apache.spark.sql.types.{ArrayType, IntegerType, StringType, StructField, StructType, LongType}\nimport org.apache.hadoop.fs.{FileSystem, Path}\nval fs \u003d FileSystem.get(spark.sparkContext.hadoopConfiguration)\nimport scala.util.parsing.json.JSON"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Get data from URL\n\nThis function takes a URL as an argument and returns the response from that URL after executing a GET request."
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def ExecuteHttpGet(url: String) : Option[String] \u003d {\n\n  val client: OkHttpClient \u003d new OkHttpClient();\n\n  val headerBuilder \u003d new Headers.Builder\n  val headers \u003d headerBuilder\n    .add(\"content-type\", \"application/json\")\n    .build\n\n  val result \u003d try {\n      val request \u003d new Request.Builder()\n        .url(url)\n        .headers(headers)\n        .build();\n\n      val response: Response \u003d client.newCall(request).execute()\n      response.body().string()\n    }\n    catch {\n      case _: Throwable \u003d\u003e null\n    }\n\n  Option[String](result)\n}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Getting Station Status Data from Citi-Bike\n\nThis function gets the station status data from Citi Bike by requesting data from https://gbfs.citibikenyc.com/gbfs/en/station_status.json\n\nWe then parse the data as JSON and then use Spark\u0027s DataFrame API to filter those stations where the following conditions are met\n- **`is_renting` is True**: these are stations that are currently renting bikes\n- **`is_installed` is True**: these are stations that currently have a dock installed\n- **`is_returning` is True**: these are stations that are currently allowing bikes to be returned\n- **`station_status` is \u0027active\u0027**: these are stations that are currently active\n\nWe then select the columns `station_id`, which is the unique id that is associated with each station, and `num_bikes_available`, which is the number of bikes available at that station.\n\nWe then return the data as a DataFrame"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def GetStatusDF() : org.apache.spark.sql.DataFrame \u003d {\n    val jsonStr \u003d ExecuteHttpGet(\"https://gbfs.citibikenyc.com/gbfs/en/station_status.json\").getOrElse(\"\")\n    val status_df_raw \u003d spark.read.json(Seq(jsonStr).toDS)\n    status_df_raw.withColumn(\"data\", explode($\"data.stations\"))\n       .select(\"data.*\")\n       .filter($\"is_renting\" \u003d\u003d\u003d 1 \u0026\u0026 $\"is_installed\" \u003d\u003d\u003d 1 \u0026\u0026 $\"is_returning\" \u003d\u003d\u003d 1 \u0026\u0026 $\"station_status\" \u003d\u003d\u003d \"active\")\n       .select(\"station_id\",\n               \"num_bikes_available\"\n               )\n}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Getting Station Information Data from Citi-Bike\n\nThis function gets the station information data from Citi Bike by requesting data from https://gbfs.citibikenyc.com/gbfs/en/station_information.json\n\nWe then parse the data as JSON and then use Spark\u0027s DataFrame API to filter those stations where the following conditions are met\n- **`capacity` is not 0**: capacity should be non-zero for the station to have returns\n- **`lat` and `lon` are not 0**: stations that have 0 latitude and longitude are virtual stations\n\nWe then select the follwing columns and return the data as a DataFrame\n\n- `station_id`\n- `capacity`\n- `lon`\n- `lat`\n- `name`"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def GetInfoDF() : org.apache.spark.sql.DataFrame \u003d {\n    val jsonStr \u003d ExecuteHttpGet(\"https://gbfs.citibikenyc.com/gbfs/en/station_information.json\").getOrElse(\"\")\n    val status_df_raw \u003d spark.read.json(Seq(jsonStr).toDS)\n    status_df_raw.withColumn(\"data\", explode($\"data.stations\"))\n       .select(\"data.*\")\n       .filter(!($\"capacity\" \u003d\u003d\u003d 0 || $\"lon\" \u003d\u003d\u003d 0 || $\"lat\" \u003d\u003d\u003d 0))\n       .select(\"station_id\",\n               \"capacity\",\n               \"lon\",\n               \"lat\",\n               \"name\")\n}\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Calculating Discounts\n\nThe function `getDiscounts` takes a station status DataFrame and the latitude and longitude of the user to calculate discounts.\n\nWe first take the input status DataFrame and join it with the current information DataFrame on the column `station_id`.\n\nThen, we calculate the availability of bikes at each station as `num_bikes_available / capacity`\n\nThe `calculateDistance` function takes the latitudes and longitudes of two locations as arguments and returns the distance between them in miles. We use this function to calculate the distance of each station from the user.\n\nWe then filter all stations that have an availability of less than 40% and are within a 0.8 mile radius from the user.\n\nA reward value is calculated for each station which is directly proportional to the distance (users should get more discounts for dropping bikes at locations that are farther away), and inversely proportional to the availability at that station.\n\nWe normalize the value of reward between 10% and 20% to calculate the total discount. We also add an additional 5% discount for station with availabilty \\\u003c10%\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def calculateDistance \u003d udf((lat1:Double, lon1:Double,lat2:Double, lon2:Double)\u003d\u003e{\n    val AVERAGE_RADIUS_OF_EARTH \u003d 3958.8\n    val latDistance \u003d Math.toRadians(lat1 - lat2)\n    val lngDistance \u003d Math.toRadians(lon1 - lon2)\n    val sinLat \u003d Math.sin(latDistance / 2)\n    val sinLng \u003d Math.sin(lngDistance / 2)\n    val a \u003d sinLat * sinLat +\n    (Math.cos(Math.toRadians(lat1)) *\n        Math.cos(Math.toRadians(lat2)) *\n        sinLng * sinLng)\n    val c \u003d 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a))\n    (AVERAGE_RADIUS_OF_EARTH * c)\n})\n\ndef filterByAvailability \u003d udf((availability:Double)\u003d\u003e{\n    availability \u003c 0.4\n})\n\ndef filterByDistance \u003d udf((distance:Double)\u003d\u003e{\n    distance \u003c 0.8\n})\n\ndef calculateReward \u003d udf((availability:Double, distance:Double)\u003d\u003e{\n    \n    1 * distance/(if(availability \u003d\u003d 0) 0.05 else availability)\n})\n\ndef formatDiscount \u003d udf((value:Double) \u003d\u003e {\n    ((math floor value * 100) / 100) + \"%\"\n})\n\ndef formatLocation \u003d udf((lat:Double, lon:Double) \u003d\u003e {\n    lat + \",\" + lon\n})\n\ndef formatDistance \u003d udf((distance:Double) \u003d\u003e {\n    ((math floor distance * 100) / 100) + \" miles\"\n})\n\ndef formatAvail \u003d udf((value:Double) \u003d\u003e {\n    ((math floor value * 10000) / 100) + \"%\"\n})\n\n\ncase class StationData(\n    station_id: String,\n    num_bikes_available: Long,\n    capacity: Long,\n    distance: Double,\n    lon: Double,\n    lat: Double,\n    name: String,\n    availability: Double,\n    reward: Double\n)\n\ndef getDiscounts \u003d (statusDf: org.apache.spark.sql.DataFrame, source_lat: Double, source_lon: Double) \u003d\u003e {\n    \n    val infoDf \u003d GetInfoDF()\n    \n    val df \u003d statusDf.join(infoDf,Seq(\"station_id\"),\"inner\")\n                     .withColumn(\"availability\",col(\"num_bikes_available\")/col(\"capacity\"))\n                     .withColumn(\"source_lat\",lit(source_lat))\n                     .withColumn(\"source_lon\",lit(source_lon))\n                     .withColumn(\"distance\", calculateDistance(col(\"lat\"), col(\"lon\"),col(\"source_lat\"), col(\"source_lon\")))\n                     .withColumn(\"reward\", calculateReward(col(\"availability\"), col(\"distance\")))\n                     .as[StationData]\n                     \n    val t \u003d df.filter(filterByDistance($\"distance\"))\n              .filter(filterByAvailability($\"availability\"))\n    \n    val (max_r,min_r) \u003d t.select(max(\"reward\"), min(\"reward\"))\n                         .as[(Double, Double)]\n                         .first()\n                         \n    val finalDf \u003d t.withColumn(\"discountVal\",  when($\"availability\".gt(0.1), (($\"reward\" - min_r) * 10/ (max_r - min_r) + 10))\n                                              .otherwise((($\"reward\" - min_r) * 10/ (max_r - min_r) + 15)))\n                  .withColumn(\"discount\", formatDiscount(col(\"discountVal\")))\n                  .withColumn(\"location\", formatLocation(col(\"lat\"), col(\"lon\")))\n                  .withColumn(\"distance\", formatDistance(col(\"distance\")))\n                  .withColumn(\"availability\", formatAvail(col(\"availability\")))\n                  .sort(col(\"discountVal\").desc)\n                  .select(\"station_id\", \"name\", \"location\", \"num_bikes_available\", \"capacity\", \"distance\", \"availability\", \"discount\")\n    z.show(finalDf)\n    finalDf\n}\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n### Demo of calculating discounts at current time\n\nA user can input their current location in the textbox in the next cell and we can call `GetStatusDF()` to get the current status of stations and calculate discounts by calling `getDiscounts(currentStatus, user_lat, user_lon)`"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val coordinates \u003d (\"\" + z.textbox(\"latitude, longitude\")).split(\",\").map(_.trim)\n\nval user_lat \u003d coordinates(0).toDouble\nval user_lon \u003d coordinates(1).toDouble"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val currentStatus \u003d GetStatusDF()\ngetDiscounts(currentStatus, user_lat, user_lon)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Predicting Bike Availability at a Given Time \n\nThe function `getPredictedStatusDf` takes as a time string in the format \"HH:MM\" as an argument and returns a DataFrame representing the predicted bike availability at that time.\n\nWe have stored the `station_status.json` files for an entire day in the directory `citibike_files/files/`. For our project this is data for a single day, but we can use data for an entire week and use the data for the same weekday as the user requests to improve the accuracy of our prediction.\n\nWe filter files which have data for times within 10 minutes of the requested time. We then parse all these files and get a pair RDD of `(station_id, num_bikes_available)`\n\nWe use this pair RDD to calculate the average number of bikes available at each station at the given time and return the result as a DataFrame"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def getPredictedStatusDf \u003d (inputTime: String) \u003d\u003e {\n    val paths \u003d sc.parallelize(fs.listStatus(new Path(\"/user/aj3187_nyu_edu/citibike_files/files/\")).map(_.getPath.toString))\n    val queryTime \u003d inputTime.split(\":\").map(_.trim)\n    val timeInMinutes \u003d queryTime(0).toInt * 60 + queryTime(1).toInt\n    \n    val pathsDf \u003d paths.toDF(\"files\")\n                   .withColumn(\"ts\", $\"files\".substr(64,10))\n                   .withColumn(\"time\", from_unixtime($\"ts\"))\n                   .withColumn(\"minutes\", minute($\"time\"))\n                   .withColumn(\"hour\", hour($\"time\"))\n                   .withColumn(\"totalMinutes\", $\"hour\" * 60 + $\"minutes\")\n                   .filter(abs($\"totalMinutes\" - timeInMinutes) \u003c 10)\n                   .select(\"files\")\n                   \n    val pathsString \u003d pathsDf.rdd.map(p \u003d\u003e p(0).toString).collect().mkString(\",\")\n    \n    val jsonsRdd \u003d sc.textFile(pathsString)\n    \n    val statusData \u003d jsonsRdd.flatMap(\n                    r \u003d\u003e JSON.parseFull(r).getOrElse(0)\n                             .asInstanceOf[Map[String,Any]]\n                             .get(\"data\").getOrElse(0).asInstanceOf[Map[String,Any]]\n                             .get(\"stations\").getOrElse(0).asInstanceOf[List[Map[String,String]]]\n                             .map(m \u003d\u003e m.get(\"station_id\").getOrElse(0) -\u003e m.get(\"num_bikes_available\").getOrElse(0))\n                    )\n                    .collect()\n    \n    val statusDataAvg \u003d statusData.groupBy(_._1)\n                                  .mapValues(xs \u003d\u003e xs.map(x \u003d\u003e x._2).reduce((x,y) \u003d\u003e x.toString.toDouble + y.toString.toDouble) -\u003e xs.length)\n                                  .mapValues(xs \u003d\u003e Math.ceil(xs._1.toString.toDouble / xs._2.toString.toDouble).toLong)\n                                  .toArray\n                                  .map(x \u003d\u003e x._1.toString -\u003e x._2)\n                                  \n    sc.parallelize(statusDataAvg).toDF(\"station_id\",\"num_bikes_available\")    \n}\n\n  \n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n### Demo of calculating discounts at a given time\n\nA user can input a time in the textbox in the next cell and we can call `getPredictedStatusDf(inputTime)` to get the predicted status of stations at that time and calculate discounts by calling `getDiscounts(predictedStatus, user_lat, user_lon)`"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val inputTime \u003d (\"\" + z.textbox(\"time to drop (HH:MM)\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val predictedStatus \u003d getPredictedStatusDf(inputTime)\ngetDiscounts(predictedStatus, user_lat, user_lon)"
    }
  ]
}